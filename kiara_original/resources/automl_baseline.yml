new_cluster: &new_cluster
  new_cluster:
    spark_version: 15.4.x-scala2.12
    azure_attributes:
      first_on_demand: 1
      availability: SPOT_WITH_FALLBACK_AZURE
      spot_bid_max_price: -1
    node_type_id: Standard_D4ds_v5
    spark_env_vars:
      PYSPARK_PYTHON: /databricks/python3/bin/python3
    enable_elastic_disk: true
    data_security_mode: DATA_SECURITY_MODE_DEDICATED
    runtime_engine: PHOTON
    kind: CLASSIC_PREVIEW
    use_ml_runtime: true
    is_single_node: false
    num_workers: 8
    custom_tags:
      clusterSource: mlops-stacks_0.4


common_permissions: &permissions
  permissions:
    - level: CAN_VIEW
      group_name: users

resources:
  jobs:
    run_automl_baseline:
      name: automl_baseline_job
      run_as: ${var.user_name}
      job_clusters:
        - job_cluster_key: automl_baseline_job_cluster
          <<: *new_cluster
      tasks:
        - task_key: TrainAutoMLBaseline
          job_cluster_key: automl_baseline_job_cluster
          notebook_task:
            notebook_path: ../training/notebooks/automl_baseline.ipynb
            base_parameters:
              # TODO modify these arguments to reflect your setup.
              advanced_churn_label_table: ${var.catalog_name}.${var.schema_name}.advanced_churn_label_table
              advanced_churn_feature_table: ${var.catalog_name}.${var.schema_name}.advanced_churn_feature_table
              avg_price_increase: ${var.catalog_name}.${var.schema_name}.advanced_churn_feature_table
              experiment_name: ${var.experiment_name}
              model_name: ${var.catalog_name}.${var.schema_name}.${var.model_name}
              # git source information of current ML resource deployment. It will be persisted as part of the workflow run
              git_source_info: url:${bundle.git.origin_url}; branch:${bundle.git.branch}; commit:${bundle.git.commit}
        - task_key: ValidateAutoMLBaseline
          job_cluster_key: automl_baseline_job_cluster
          depends_on:
            - task_key: TrainAutoMLBaseline
          notebook_task:
            notebook_path: ../validation/notebooks/validation.ipynb
            base_parameters:
              # TODO modify these arguments to reflect your setup.
              advanced_churn_label_table: ${var.catalog_name}.${var.schema_name}.advanced_churn_label_table
              advanced_churn_feature_table: ${var.catalog_name}.${var.schema_name}.advanced_churn_feature_table
              avg_price_increase: ${var.catalog_name}.${var.schema_name}.advanced_churn_feature_table
              experiment_name: ${var.experiment_name}
              model_name: ${var.catalog_name}.${var.schema_name}.${var.model_name}
              targets: churn
              model_alias: champion
              model_info_table: ${var.catalog_name}.${var.schema_name}.model_info_table
              # git source information of current ML resource deployment. It will be persisted as part of the workflow run
              git_source_info: url:${bundle.git.origin_url}; branch:${bundle.git.branch}; commit:${bundle.git.commit}
        - task_key: ChallengerChampionAlias
          job_cluster_key: automl_baseline_job_cluster
          depends_on:
            - task_key: ValidateAutoMLBaseline
          notebook_task:
            notebook_path: ../validation/notebooks/challenger_champion.ipynb
            base_parameters:
              # TODO modify these arguments to reflect your setup.
              model_name: ${var.catalog_name}.${var.schema_name}.${var.model_name}
              model_info_table: ${var.catalog_name}.${var.schema_name}.model_info_table
              # git source information of current ML resource deployment. It will be persisted as part of the workflow run
              git_source_info: url:${bundle.git.origin_url}; branch:${bundle.git.branch}; commit:${bundle.git.commit}       
      schedule:
        quartz_cron_expression: "0 0 7 * * ?" # daily at 7am
        timezone_id: UTC
      <<: *permissions
      # If you want to turn on notifications for this job, please uncomment the below code,
      # and provide a list of emails to the on_failure argument.
      #
      #  email_notifications:
      #    on_failure:
      #      - first@company.com
      #      - second@company.com
